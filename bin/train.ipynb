{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.pooling import MaxPooling3D, GlobalAveragePooling3D, AveragePooling3D\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import he_uniform\n",
    "import htmd.ui as ht\n",
    "import htmd.molecule.voxeldescriptors as vd\n",
    "import htmd.vmdviewer as vmdviewer\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import *\n",
    "import bcolz as bc\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(summary=False):\n",
    "    \"\"\" Return the Keras model of the network\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1st layer group\n",
    "    model.add(Conv3D(filters=32,\n",
    "                     kernel_size=(5, 5, 5),\n",
    "                     strides = (1, 1, 1),\n",
    "                     input_shape=(50, 50, 50, 16),\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     kernel_initializer=he_uniform(seed=9876),\n",
    "                     bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2),\n",
    "                           padding='valid'))\n",
    "    \n",
    "    # 2nd layer group\n",
    "    model.add(Conv3D(filters=64,\n",
    "                     kernel_size=(3, 3, 3),\n",
    "                     strides = (1, 1, 1),\n",
    "                     activation='relu',\n",
    "                     padding='valid'))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2),\n",
    "                           padding='valid'))\n",
    "    \n",
    "    # 3rd layer group\n",
    "    model.add(Conv3D(filters=128,\n",
    "                     kernel_size=(3, 3, 3),\n",
    "                     strides = (1, 1, 1),\n",
    "                     activation='relu',\n",
    "                     padding='valid'))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2),\n",
    "                           padding='valid'))\n",
    "    \n",
    "    # 4th layer group\n",
    "#     model.add(Conv3D(filters=128,\n",
    "#                      kernel_size=(3, 3, 3),\n",
    "#                      activation='relu',\n",
    "#                      padding='valid'))\n",
    "    \n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2),\n",
    "#                            #strides=(1, 1, 1),\n",
    "#                            padding='valid'))\n",
    "    \n",
    "    #model.add(AveragePooling3D(pool_size=(2, 2, 2), \n",
    "    #                           padding='valid'))\n",
    "                           \n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "#     model.add(Dropout(.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(.5))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_16 (Conv3D)           (None, 46, 46, 46, 32)    64032     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 23, 23, 23, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 21, 21, 21, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 10, 10, 10, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 8, 8, 8, 128)      221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 4, 4, 4, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,438,369\n",
      "Trainable params: 2,438,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f26ba2fcb38>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model(summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_x_2000.pickle', 'rb') as f:\n",
    "    data_x = pickle.load(f)\n",
    "with open('data_y_2000.pickle', 'rb') as f:\n",
    "    data_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1900, 50, 50, 50, 16), (1900,), (100, 50, 50, 50, 16), (100,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = 1900\n",
    "train_x, train_y = data_x[:limit], data_y[:limit]\n",
    "test_x, test_y = data_x[limit:], data_y[limit:]\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gpus = 4\n",
    "nb_batch = nb_gpus*8\n",
    "nb_epochs = 500\n",
    "l_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.compile(optimizer=optimizers.rmsprop(lr=l_rate),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[metrics.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1900/1900 [==============================] - 39s 20ms/step - loss: 14.6309 - mean_squared_error: 14.6309\n",
      "Epoch 2/500\n",
      "1900/1900 [==============================] - 36s 19ms/step - loss: 3.0178 - mean_squared_error: 3.0178\n",
      "Epoch 7/500\n",
      "1900/1900 [==============================] - 35s 19ms/step - loss: 2.9788 - mean_squared_error: 2.9788\n",
      "Epoch 8/500\n",
      "1900/1900 [==============================] - 37s 20ms/step - loss: 2.9820 - mean_squared_error: 2.9820\n",
      "Epoch 9/500\n",
      "1900/1900 [==============================] - 37s 20ms/step - loss: 2.9612 - mean_squared_error: 2.9612\n",
      "Epoch 10/500\n",
      "1900/1900 [==============================] - 36s 19ms/step - loss: 2.9140 - mean_squared_error: 2.9140\n",
      "Epoch 11/500\n",
      "1900/1900 [==============================] - 36s 19ms/step - loss: 2.8951 - mean_squared_error: 2.8951\n",
      "Epoch 12/500\n",
      "1900/1900 [==============================] - 36s 19ms/step - loss: 2.8905 - mean_squared_error: 2.8905\n",
      "Epoch 13/500\n",
      "1900/1900 [==============================] - 37s 20ms/step - loss: 2.8383 - mean_squared_error: 2.8383\n",
      "Epoch 14/500\n",
      "1900/1900 [==============================] - 37s 19ms/step - loss: 2.8226 - mean_squared_error: 2.8226\n",
      "Epoch 15/500\n",
      "1900/1900 [==============================] - 36s 19ms/step - loss: 2.8011 - mean_squared_error: 2.8011\n",
      "Epoch 16/500\n",
      "1900/1900 [==============================] - 36s 19ms/step - loss: 2.7612 - mean_squared_error: 2.7612\n",
      "Epoch 17/500\n",
      "1900/1900 [==============================] - 34s 18ms/step - loss: 2.7753 - mean_squared_error: 2.7753\n",
      "Epoch 18/500\n",
      "1900/1900 [==============================] - 37s 20ms/step - loss: 2.7340 - mean_squared_error: 2.7340\n",
      "Epoch 19/500\n",
      "1900/1900 [==============================] - 37s 19ms/step - loss: 2.7361 - mean_squared_error: 2.7361\n",
      "Epoch 20/500\n",
      "1900/1900 [==============================] - 35s 19ms/step - loss: 2.6760 - mean_squared_error: 2.6760\n",
      "Epoch 21/500\n",
      "1900/1900 [==============================] - 35s 19ms/step - loss: 2.6478 - mean_squared_error: 2.6478\n",
      "Epoch 22/500\n",
      "1900/1900 [==============================] - 34s 18ms/step - loss: 2.6601 - mean_squared_error: 2.6601\n",
      "Epoch 23/500\n",
      "1900/1900 [==============================] - 35s 19ms/step - loss: 2.6181 - mean_squared_error: 2.6181\n",
      "Epoch 24/500\n",
      "1900/1900 [==============================] - 35s 18ms/step - loss: 2.5939 - mean_squared_error: 2.5939\n",
      "Epoch 25/500\n",
      "1900/1900 [==============================] - 35s 19ms/step - loss: 2.5782 - mean_squared_error: 2.5782\n",
      "Epoch 26/500\n",
      "1900/1900 [==============================] - 34s 18ms/step - loss: 2.5527 - mean_squared_error: 2.5527\n",
      "Epoch 27/500\n",
      "1900/1900 [==============================] - 35s 19ms/step - loss: 2.5520 - mean_squared_error: 2.5520\n",
      "Epoch 28/500\n",
      "1900/1900 [==============================] - 35s 18ms/step - loss: 2.5237 - mean_squared_error: 2.5237\n",
      "Epoch 29/500\n",
      "1900/1900 [==============================] - 37s 19ms/step - loss: 2.4901 - mean_squared_error: 2.4901\n",
      "Epoch 30/500\n",
      "1900/1900 [==============================] - 40s 21ms/step - loss: 2.4636 - mean_squared_error: 2.4636\n",
      "Epoch 31/500\n",
      "1900/1900 [==============================] - 46s 24ms/step - loss: 2.4359 - mean_squared_error: 2.4359\n",
      "Epoch 32/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.4073 - mean_squared_error: 2.4073\n",
      "Epoch 33/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.4062 - mean_squared_error: 2.4062\n",
      "Epoch 34/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 2.4259 - mean_squared_error: 2.4259\n",
      "Epoch 35/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 2.3561 - mean_squared_error: 2.3561\n",
      "Epoch 36/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.3281 - mean_squared_error: 2.3281\n",
      "Epoch 37/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 2.3309 - mean_squared_error: 2.3309\n",
      "Epoch 38/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.2925 - mean_squared_error: 2.2925\n",
      "Epoch 39/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.2750 - mean_squared_error: 2.2750\n",
      "Epoch 40/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 2.2512 - mean_squared_error: 2.2512\n",
      "Epoch 41/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 2.2309 - mean_squared_error: 2.2309\n",
      "Epoch 42/500\n",
      "1900/1900 [==============================] - 45s 23ms/step - loss: 2.2234 - mean_squared_error: 2.2234\n",
      "Epoch 43/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.1946 - mean_squared_error: 2.1946\n",
      "Epoch 44/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 2.1972 - mean_squared_error: 2.1972\n",
      "Epoch 45/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.1685 - mean_squared_error: 2.1685\n",
      "Epoch 46/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.1302 - mean_squared_error: 2.1302\n",
      "Epoch 47/500\n",
      "1900/1900 [==============================] - 42s 22ms/step - loss: 2.1297 - mean_squared_error: 2.1297\n",
      "Epoch 48/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.1461 - mean_squared_error: 2.1461\n",
      "Epoch 49/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.0832 - mean_squared_error: 2.0832\n",
      "Epoch 50/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 2.0683 - mean_squared_error: 2.0683\n",
      "Epoch 51/500\n",
      "1900/1900 [==============================] - 42s 22ms/step - loss: 2.0476 - mean_squared_error: 2.0476\n",
      "Epoch 52/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.0431 - mean_squared_error: 2.0431\n",
      "Epoch 53/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 2.0250 - mean_squared_error: 2.0250\n",
      "Epoch 54/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 2.0207 - mean_squared_error: 2.0207\n",
      "Epoch 55/500\n",
      " 448/1900 [======>.......................] - ETA: 32s - loss: 2.1056 - mean_squared_error: 2.1056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.5232 - mean_squared_error: 0.5232\n",
      "Epoch 167/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.4990 - mean_squared_error: 0.4990\n",
      "Epoch 168/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.5002 - mean_squared_error: 0.5002\n",
      "Epoch 169/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.5030 - mean_squared_error: 0.5030\n",
      "Epoch 170/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4758 - mean_squared_error: 0.4758\n",
      "Epoch 171/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.4667 - mean_squared_error: 0.4667\n",
      "Epoch 172/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4666 - mean_squared_error: 0.4666\n",
      "Epoch 173/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4582 - mean_squared_error: 0.4582\n",
      "Epoch 174/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4351 - mean_squared_error: 0.4351\n",
      "Epoch 175/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4530 - mean_squared_error: 0.4530\n",
      "Epoch 176/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4460 - mean_squared_error: 0.4460\n",
      "Epoch 177/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.4234 - mean_squared_error: 0.4234\n",
      "Epoch 178/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.4472 - mean_squared_error: 0.4472\n",
      "Epoch 179/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.4429 - mean_squared_error: 0.4429\n",
      "Epoch 180/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.4070 - mean_squared_error: 0.4070\n",
      "Epoch 181/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.4298 - mean_squared_error: 0.4298\n",
      "Epoch 182/500\n",
      "1900/1900 [==============================] - 45s 23ms/step - loss: 0.3989 - mean_squared_error: 0.3989\n",
      "Epoch 183/500\n",
      "1900/1900 [==============================] - 42s 22ms/step - loss: 0.3984 - mean_squared_error: 0.3984\n",
      "Epoch 184/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3994 - mean_squared_error: 0.3994\n",
      "Epoch 185/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.4038 - mean_squared_error: 0.4038\n",
      "Epoch 186/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3665 - mean_squared_error: 0.3665\n",
      "Epoch 187/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3942 - mean_squared_error: 0.3942\n",
      "Epoch 188/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3531 - mean_squared_error: 0.3531\n",
      "Epoch 189/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.3662 - mean_squared_error: 0.3662\n",
      "Epoch 190/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3424 - mean_squared_error: 0.3424\n",
      "Epoch 191/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3606 - mean_squared_error: 0.3606\n",
      "Epoch 192/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.3331 - mean_squared_error: 0.3331\n",
      "Epoch 193/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.3619 - mean_squared_error: 0.3619\n",
      "Epoch 194/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.3579 - mean_squared_error: 0.3579\n",
      "Epoch 195/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.3179 - mean_squared_error: 0.3179\n",
      "Epoch 196/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.3475 - mean_squared_error: 0.3475\n",
      "Epoch 197/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3202 - mean_squared_error: 0.3202\n",
      "Epoch 198/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.3184 - mean_squared_error: 0.3184\n",
      "Epoch 199/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3166 - mean_squared_error: 0.3166\n",
      "Epoch 200/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.3035 - mean_squared_error: 0.3035\n",
      "Epoch 201/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3172 - mean_squared_error: 0.3172\n",
      "Epoch 202/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3056 - mean_squared_error: 0.3056\n",
      "Epoch 203/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.3056 - mean_squared_error: 0.3056\n",
      "Epoch 204/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.3114 - mean_squared_error: 0.3114\n",
      "Epoch 205/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.2900 - mean_squared_error: 0.2900\n",
      "Epoch 206/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.3004 - mean_squared_error: 0.3004\n",
      "Epoch 207/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.2734 - mean_squared_error: 0.2734\n",
      "Epoch 208/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.2843 - mean_squared_error: 0.2843\n",
      "Epoch 209/500\n",
      "1900/1900 [==============================] - 41s 22ms/step - loss: 0.2774 - mean_squared_error: 0.2774\n",
      "Epoch 210/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.2713 - mean_squared_error: 0.2713\n",
      "Epoch 211/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.2727 - mean_squared_error: 0.2727\n",
      "Epoch 212/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.2596 - mean_squared_error: 0.2596\n",
      "Epoch 213/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.2661 - mean_squared_error: 0.2661\n",
      "Epoch 214/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.2571 - mean_squared_error: 0.2571\n",
      "Epoch 215/500\n",
      " 352/1900 [====>.........................] - ETA: 28s - loss: 0.3118 - mean_squared_error: 0.3118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0922 - mean_squared_error: 0.0922\n",
      "Epoch 330/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0882 - mean_squared_error: 0.0882\n",
      "Epoch 331/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0940 - mean_squared_error: 0.0940\n",
      "Epoch 332/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0896 - mean_squared_error: 0.0896\n",
      "Epoch 333/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0879 - mean_squared_error: 0.0879\n",
      "Epoch 334/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.0901 - mean_squared_error: 0.0901\n",
      "Epoch 335/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0936 - mean_squared_error: 0.0936\n",
      "Epoch 336/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0891 - mean_squared_error: 0.0891\n",
      "Epoch 337/500\n",
      "1900/1900 [==============================] - 45s 23ms/step - loss: 0.0916 - mean_squared_error: 0.0916\n",
      "Epoch 338/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0844 - mean_squared_error: 0.0844\n",
      "Epoch 339/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0888 - mean_squared_error: 0.0888\n",
      "Epoch 340/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.0873 - mean_squared_error: 0.0873\n",
      "Epoch 341/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0916 - mean_squared_error: 0.0916\n",
      "Epoch 342/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.0910 - mean_squared_error: 0.0910\n",
      "Epoch 343/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0837 - mean_squared_error: 0.0837\n",
      "Epoch 344/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0852 - mean_squared_error: 0.0852\n",
      "Epoch 345/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0797 - mean_squared_error: 0.0797\n",
      "Epoch 346/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0901 - mean_squared_error: 0.0901\n",
      "Epoch 347/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0808 - mean_squared_error: 0.0808\n",
      "Epoch 348/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0809 - mean_squared_error: 0.0809\n",
      "Epoch 349/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.0854 - mean_squared_error: 0.0854\n",
      "Epoch 350/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0790 - mean_squared_error: 0.0790\n",
      "Epoch 351/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0735 - mean_squared_error: 0.0735\n",
      "Epoch 352/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0855 - mean_squared_error: 0.0855\n",
      "Epoch 353/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0862 - mean_squared_error: 0.0862\n",
      "Epoch 354/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
      "Epoch 355/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0739 - mean_squared_error: 0.0739\n",
      "Epoch 356/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0830 - mean_squared_error: 0.0830\n",
      "Epoch 357/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.0795 - mean_squared_error: 0.0795\n",
      "Epoch 358/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0829 - mean_squared_error: 0.0829\n",
      "Epoch 359/500\n",
      "1900/1900 [==============================] - 42s 22ms/step - loss: 0.0773 - mean_squared_error: 0.0773\n",
      "Epoch 360/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0771 - mean_squared_error: 0.0771\n",
      "Epoch 361/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.0820 - mean_squared_error: 0.0820\n",
      "Epoch 362/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0718 - mean_squared_error: 0.0718\n",
      "Epoch 363/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0801 - mean_squared_error: 0.0801\n",
      "Epoch 364/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0750 - mean_squared_error: 0.0750\n",
      "Epoch 365/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0809 - mean_squared_error: 0.0809\n",
      "Epoch 366/500\n",
      "1900/1900 [==============================] - 43s 22ms/step - loss: 0.0746 - mean_squared_error: 0.0746\n",
      "Epoch 367/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0762 - mean_squared_error: 0.0762\n",
      "Epoch 368/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0707 - mean_squared_error: 0.0707\n",
      "Epoch 369/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0801 - mean_squared_error: 0.0801\n",
      "Epoch 370/500\n",
      "1900/1900 [==============================] - 45s 23ms/step - loss: 0.0771 - mean_squared_error: 0.0771\n",
      "Epoch 371/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0741 - mean_squared_error: 0.0741\n",
      "Epoch 372/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0767 - mean_squared_error: 0.0767\n",
      "Epoch 373/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0755 - mean_squared_error: 0.0755\n",
      "Epoch 374/500\n",
      "1900/1900 [==============================] - 43s 23ms/step - loss: 0.0727 - mean_squared_error: 0.0727\n",
      "Epoch 375/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0713 - mean_squared_error: 0.0713\n",
      "Epoch 376/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0707 - mean_squared_error: 0.0707\n",
      "Epoch 377/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0754 - mean_squared_error: 0.0754\n",
      "Epoch 378/500\n",
      "1900/1900 [==============================] - 42s 22ms/step - loss: 0.0758 - mean_squared_error: 0.0758\n",
      "Epoch 379/500\n",
      " 128/1900 [=>............................] - ETA: 37s - loss: 0.0262 - mean_squared_error: 0.0262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.0447 - mean_squared_error: 0.0447\n",
      "Epoch 495/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0441 - mean_squared_error: 0.0441\n",
      "Epoch 496/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0440 - mean_squared_error: 0.0440\n",
      "Epoch 497/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0431 - mean_squared_error: 0.0431\n",
      "Epoch 498/500\n",
      "1900/1900 [==============================] - 42s 22ms/step - loss: 0.0447 - mean_squared_error: 0.0447\n",
      "Epoch 499/500\n",
      "1900/1900 [==============================] - 44s 23ms/step - loss: 0.0450 - mean_squared_error: 0.0450\n",
      "Epoch 500/500\n",
      "1900/1900 [==============================] - 45s 24ms/step - loss: 0.0458 - mean_squared_error: 0.0458\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_x, y=train_y, epochs=nb_epochs, batch_size=nb_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.987 , Test R2: 0.491\n"
     ]
    }
   ],
   "source": [
    "train_r2 = r2_score(y_pred=model.predict(train_x), y_true=train_y)\n",
    "test_r2 = r2_score(y_pred=model.predict(test_x), y_true=test_y)\n",
    "print(\"Train R2: %0.3f , Test R2: %0.3f\" % (train_r2, test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(['Train'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
