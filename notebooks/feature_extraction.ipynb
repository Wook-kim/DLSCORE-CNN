{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "from tqdm import *\n",
    "import os\n",
    "from scipy import spatial\n",
    "import pybel\n",
    "from oddt import toolkit\n",
    "from oddt import datasets\n",
    "# ODDT documentation: https://pythonhosted.org/oddt/\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append(\"scripts\")\n",
    "from elements import ELEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "data_dir = \"data\"\n",
    "pdbbind_dir = \"/home/PDBbind/pdbbind_2016/refined-set-2016\"\n",
    "binding_pocket_dir = \"/home/PDBbind/pdbbind_2016/binding_pockets_refined\"\n",
    "pdbbind_dataset = datasets.pdbbind(home=pdbbind_dir, default_set='refined', version=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overriding the datasets._pdbbind_id class to get the different pocket files than the original one\n",
    "class PDB(datasets._pdbbind_id):\n",
    "    def __init__(self, home, pocket_dir, pdbid, opt=None):\n",
    "        self.pocket_dir = pocket_dir\n",
    "        datasets._pdbbind_id.__init__(self, home, pdbid, opt=None)\n",
    "    \n",
    "    @property\n",
    "    def pocket(self):\n",
    "        f = os.path.join(self.pocket_dir, '%s_complex2.pdb' % self.id)\n",
    "        if os.path.isfile(f):\n",
    "            pocket = next(toolkit.readfile('pdb', f, lazy=True, opt=self.opt))\n",
    "            if pocket is not None:\n",
    "                pocket.protein = True\n",
    "            return pocket\n",
    "        else:\n",
    "            return None        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reshape(x):\n",
    "    \"\"\"\n",
    "    Method for reshaping a sample to the desired one.\n",
    "    :param x\n",
    "    \"\"\"\n",
    "    new_shape = [24, 24, 24, 16]\n",
    "    dim_diff = np.array([i-j for i, j in zip(new_shape, x.shape)])\n",
    "    pad_dim = np.round(dim_diff / 2).astype(int)\n",
    "    x = np.pad(x, [(pad_dim[0], dim_diff[0]-pad_dim[0]),\n",
    "                   (pad_dim[1], dim_diff[1]-pad_dim[1]),\n",
    "                   (pad_dim[2], dim_diff[2]-pad_dim[2]),\n",
    "                   (0, 0)],\n",
    "               'constant')\n",
    "    \n",
    "    return x\n",
    "    #return x[13:37, 13:37, 13:37, :]\n",
    "    #return x[5:45, 5:45, 5:45, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Van daar Waals radii for all the elements\n",
    "element_radii = {'Ac': 2.0, 'Ag': 1.72, 'Al': 2.0, 'Am': 2.0, 'Ar': 1.88, 'As': 1.85, 'At': 2.0, 'Au': 1.66,\n",
    "                 'B': 2.0, 'Ba': 2.0, 'Be': 2.0, 'Bh': 2.0, 'Bi': 2.0, 'Bk': 2.0, 'Br': 1.85, 'C': 1.7, 'Ca': 1.37,\n",
    "                 'Cd': 1.58, 'Ce': 2.0, 'Cf': 2.0, 'Cl': 2.27, 'Cm': 2.0, 'Co': 2.0, 'Cr': 2.0, 'Cs': 2.1, 'Cu': 1.4,\n",
    "                 'Db': 2.0, 'Ds': 2.0, 'Dy': 2.0, 'Er': 2.0, 'Es': 2.0, 'Eu': 2.0, 'F': 1.47, 'Fe': 2.0, 'Fm': 2.0,\n",
    "                 'Fr': 2.0, 'Ga': 1.07, 'Gd': 2.0, 'Ge': 2.0, 'H': 1.2, 'He': 1.4, 'Hf': 2.0, 'Hg': 1.55, 'Ho': 2.0,\n",
    "                 'Hs': 2.0, 'I': 1.98, 'In': 1.93, 'Ir': 2.0, 'K': 1.76, 'Kr': 2.02, 'La': 2.0, 'Li': 1.82, 'Lr': 2.0,\n",
    "                 'Lu': 2.0, 'Md': 2.0, 'Mg': 1.18, 'Mn': 2.0, 'Mo': 2.0, 'Mt': 2.0, 'N': 1.55, 'Na': 1.36, 'Nb': 2.0,\n",
    "                 'Nd': 2.0, 'Ne': 1.54, 'Ni': 1.63, 'No': 2.0, 'Np': 2.0, 'O': 1.52, 'Os': 2.0, 'P': 1.8, 'Pa': 2.0,\n",
    "                 'Pb': 2.02, 'Pd': 1.63, 'Pm': 2.0, 'Po': 2.0, 'Pr': 2.0, 'Pt': 1.72, 'Pu': 2.0, 'Ra': 2.0, 'Rb': 2.0,\n",
    "                 'Re': 2.0, 'Rf': 2.0, 'Rg': 2.0, 'Rh': 2.0, 'Rn': 2.0, 'Ru': 2.0, 'S': 1.8, 'Sb': 2.0, 'Sc': 2.0,\n",
    "                 'Se': 1.9, 'Sg': 2.0, 'Si': 2.1, 'Sm': 2.0, 'Sn': 2.17, 'Sr': 2.0, 'Ta': 2.0, 'Tb': 2.0, 'Tc': 2.0,\n",
    "                 'Te': 2.06, 'Th': 2.0, 'Ti': 2.0, 'Tl': 1.96, 'Tm': 2.0, 'U': 1.86, 'V': 2.0, 'W': 2.0, 'X': 1.5,\n",
    "                 'Xe': 2.16, 'Y': 2.0, 'Yb': 2.0, 'Zn': 1.39, 'Zr': 2.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Nearest Neighbor features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get voxel features (Nearest neighbor feature)\n",
    "\n",
    "def get_voxel_features(pdbid, pdbbind_set='refined'):\n",
    "    if pdbbind_set == 'refined':\n",
    "        # Don't use the core set\n",
    "        if pdbid in pdbbind_dataset.sets['core'].keys():\n",
    "            #print(\"ERROR: PDBID {} IS IN CORE SET.\".format(pdbid))\n",
    "            return None\n",
    "    \n",
    "    # Read the binding pocket file\n",
    "    pdb_object = PDB(home=pdbbind_dir, pocket_dir=binding_pocket_dir, pdbid=pdbid)\n",
    "    binding_pocket = pdb_object.pocket    \n",
    "    \n",
    "    # If the binding pocket file has any error, return None\n",
    "    if binding_pocket == None:\n",
    "        #print(\"ERROR: INVALID BINDING POCKET FOR PDBID {}.\".format(pdbid))\n",
    "        return None\n",
    "    \n",
    "    # Get the filters for protein and ligands\n",
    "    filter_proteins = [atom.residue.name != 'HOH' for atom in binding_pocket.atoms]\n",
    "    filter_ligands = [atom.residue.name == 'HOH' for atom in binding_pocket.atoms]\n",
    "    \n",
    "    # Get the properties\n",
    "    is_hydrophobic = binding_pocket.atom_dict['ishydrophobe'].reshape((-1, 1))\n",
    "    is_aromatic = binding_pocket.atom_dict['isaromatic'].reshape((-1, 1))\n",
    "    is_hbond_acceptor = binding_pocket.atom_dict['isacceptor'].reshape((-1, 1))\n",
    "    is_hbond_donor = binding_pocket.atom_dict['isdonor'].reshape((-1, 1))\n",
    "    charges = binding_pocket.atom_dict['charge']\n",
    "    is_positive = (charges < 0.0).reshape((-1, 1))\n",
    "    is_negative = (charges >= 0.0).reshape((-1, 1))\n",
    "    is_metal = binding_pocket.atom_dict['ismetal'].reshape((-1, 1))\n",
    "    is_halogen = binding_pocket.atom_dict['ishalogen'].reshape((-1, 1))\n",
    "    atom_coords = binding_pocket.atom_dict['coords']\n",
    "    properties = np.concatenate((is_hydrophobic,\n",
    "                                 is_aromatic, \n",
    "                                 is_hbond_acceptor, \n",
    "                                 is_hbond_donor, \n",
    "                                 is_positive, \n",
    "                                 is_negative, \n",
    "                                 is_metal, \n",
    "                                 is_halogen), axis=1)\n",
    "    \n",
    "    \n",
    "    # Now get the Van Dar Wals redii for each of the atoms\n",
    "    vdw_radii = np.array([element_radii[ELEMENTS[a.atomicnum].symbol] for a in binding_pocket.atoms], dtype=np.float32)\n",
    "        \n",
    "    # Multiply the vdw radii with the properties. False's will be zeros and True's will be the vdw radii\n",
    "    properties = vdw_radii[:, np.newaxis] * properties\n",
    "    \n",
    "    # Get the features for proteins and ligands\n",
    "    features = np.zeros((len(binding_pocket.atoms), 16))\n",
    "    features[filter_proteins, :8] = properties[filter_proteins]\n",
    "    features[filter_ligands, 8:] = properties[filter_ligands]\n",
    "    \n",
    "    # Get the bounding box for the molecule\n",
    "    max_coord = np.max(atom_coords, axis=0) # np.squeeze?\n",
    "    min_coord = np.min(atom_coords, axis=0) # np.squeeze?\n",
    "\n",
    "    # Calculate the number of voxels required\n",
    "    voxel_side = 2\n",
    "    N = np.ceil((max_coord - min_coord) / voxel_side).astype(int) + 1\n",
    "\n",
    "    # Get the centers of each descriptors\n",
    "    xrange = [min_coord[0] + voxel_side * x for x in range(0, N[0])]\n",
    "    yrange = [min_coord[1] + voxel_side * x for x in range(0, N[1])]\n",
    "    zrange = [min_coord[2] + voxel_side * x for x in range(0, N[2])]\n",
    "    centers = np.zeros((N[0], N[1], N[2], 3))\n",
    "\n",
    "    for i, x in enumerate(xrange):\n",
    "        for j, y in enumerate(yrange):\n",
    "            for k, z in enumerate(zrange):\n",
    "                centers[i, j, k, :] = np.array([x, y, z])\n",
    "\n",
    "    centers = centers.reshape((-1, 3))\n",
    "    \n",
    "    voxel_features = np.zeros((len(centers), features.shape[1]), dtype=np.float32)\n",
    "    for i in range(len(binding_pocket.atoms)):\n",
    "        # Get the coordinates of the current atom\n",
    "        atom_coordinate = atom_coords[i]\n",
    "        \n",
    "        # Get the closest voxel\n",
    "        c_voxel_id = spatial.distance.cdist(atom_coordinate.reshape((-1, 3)), centers).argmin()\n",
    "        c_voxel = centers[c_voxel_id] # nearest voxel\n",
    "        \n",
    "        # Calculate the potential\n",
    "        voxel_distance = np.linalg.norm(atom_coordinate - c_voxel)\n",
    "        x = features[i] / voxel_distance\n",
    "        n = 1.0 - np.exp(-np.power(x, 12))\n",
    "        voxel_features[c_voxel_id] = n #features[i]\n",
    "        \n",
    "    voxel_features = voxel_features.reshape((N[0], N[1], N[2], -1))\n",
    "    \n",
    "    return _reshape(voxel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428f13051b0f43d1b6ac78079112df12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/ipykernel_launcher.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  import sys\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #666 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pdb_ids = []\n",
    "pdb_features = []\n",
    "\n",
    "# Get the features for all the pdbbind refined complexes\n",
    "for pdbid in tqdm_notebook(pdbbind_dataset.sets['refined'].keys()):\n",
    "    feat = get_voxel_features(pdbid=pdbid, pdbbind_set='refined')\n",
    "    if feat == None: continue    \n",
    "\n",
    "    # Save features\n",
    "    pdb_ids.append(pdbid)\n",
    "    pdb_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of features as numpy array\n",
    "data_x = np.array(pdb_features, dtype=np.float32)\n",
    "data_y = np.array([pdbbind_dataset.sets['refined'][_id] for _id in pdb_ids], dtype=np.float32)\n",
    "\n",
    "print(data_x.shape, data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3012, 24, 24, 24, 16) (377, 24, 24, 24, 16) (376, 24, 24, 24, 16)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, random_state=1)\n",
    "test_x, valid_x, test_y, valid_y = train_test_split(test_x, test_y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "h5f = h5py.File(os.path.join(data_dir, \"data_nearest_neighbor.h5\"), 'w')\n",
    "h5f.create_dataset('train_x', data=train_x)\n",
    "h5f.create_dataset('train_y', data=train_y)\n",
    "h5f.create_dataset('valid_x', data=valid_x)\n",
    "h5f.create_dataset('valid_y', data=valid_y)\n",
    "h5f.create_dataset('test_x', data=test_x)\n",
    "h5f.create_dataset('test_y', data=test_y)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genrating distributed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get voxel features (distributed features)\n",
    "\n",
    "def get_voxel_features2(pdbid, pdbbind_set='refined'):\n",
    "    if pdbbind_set == 'refined':\n",
    "        # Don't use the core set\n",
    "        if pdbid in pdbbind_dataset.sets['core'].keys():\n",
    "            #print(\"ERROR: PDBID {} IS IN CORE SET.\".format(pdbid))\n",
    "            return None\n",
    "    \n",
    "    # Read the binding pocket file\n",
    "    pdb_object = PDB(home=pdbbind_dir, pocket_dir=binding_pocket_dir, pdbid=pdbid)\n",
    "    binding_pocket = pdb_object.pocket  \n",
    "    \n",
    "    # If the binding pocket file has any error, return None\n",
    "    if binding_pocket == None:\n",
    "        #print(\"ERROR: INVALID BINDING POCKET FOR PDBID {}.\".format(pdbid))\n",
    "        return None\n",
    "    \n",
    "    # Get the filters for protein and ligands\n",
    "    filter_proteins = [atom.residue.name != 'HOH' for atom in binding_pocket.atoms]\n",
    "    filter_ligands = [atom.residue.name == 'HOH' for atom in binding_pocket.atoms]\n",
    "    \n",
    "    # Get the properties\n",
    "    is_hydrophobic = binding_pocket.atom_dict['ishydrophobe'].reshape((-1, 1))\n",
    "    is_aromatic = binding_pocket.atom_dict['isaromatic'].reshape((-1, 1))\n",
    "    is_hbond_acceptor = binding_pocket.atom_dict['isacceptor'].reshape((-1, 1))\n",
    "    is_hbond_donor = binding_pocket.atom_dict['isdonor'].reshape((-1, 1))\n",
    "    charges = binding_pocket.atom_dict['charge']\n",
    "    is_positive = (charges < 0.0).reshape((-1, 1))\n",
    "    is_negative = (charges >= 0.0).reshape((-1, 1))\n",
    "    is_metal = binding_pocket.atom_dict['ismetal'].reshape((-1, 1))\n",
    "    is_halogen = binding_pocket.atom_dict['ishalogen'].reshape((-1, 1))\n",
    "    atom_coords = binding_pocket.atom_dict['coords']\n",
    "    properties = np.concatenate((is_hydrophobic,\n",
    "                                 is_aromatic, \n",
    "                                 is_hbond_acceptor, \n",
    "                                 is_hbond_donor, \n",
    "                                 is_positive, \n",
    "                                 is_negative, \n",
    "                                 is_metal, \n",
    "                                 is_halogen), axis=1)\n",
    "    \n",
    "    \n",
    "    # Now get the Van Dar Wals redii for each of the atoms\n",
    "    vdw_radii = np.array([element_radii[ELEMENTS[a.atomicnum].symbol] for a in binding_pocket.atoms], dtype=np.float32)\n",
    "        \n",
    "    # Multiply the vdw radii with the properties. False's will be zeros and True's will be the vdw radii\n",
    "    properties = vdw_radii[:, np.newaxis] * properties\n",
    "    \n",
    "    # Get the features for proteins and ligands\n",
    "    features = np.zeros((len(binding_pocket.atoms), 16))\n",
    "    features[filter_proteins, :8] = properties[filter_proteins]\n",
    "    features[filter_ligands, 8:] = properties[filter_ligands]\n",
    "    \n",
    "    # Get the bounding box for the molecule\n",
    "    max_coord = np.max(atom_coords, axis=0) # np.squeeze?\n",
    "    min_coord = np.min(atom_coords, axis=0) # np.squeeze?\n",
    "\n",
    "    # Calculate the number of voxels required\n",
    "    voxel_side = 2\n",
    "    N = np.ceil((max_coord - min_coord) / voxel_side).astype(int) + 1\n",
    "\n",
    "    # Get the centers of each descriptors\n",
    "    xrange = [min_coord[0] + voxel_side * x for x in range(0, N[0])]\n",
    "    yrange = [min_coord[1] + voxel_side * x for x in range(0, N[1])]\n",
    "    zrange = [min_coord[2] + voxel_side * x for x in range(0, N[2])]\n",
    "    centers = np.zeros((N[0], N[1], N[2], 3))\n",
    "\n",
    "    for i, x in enumerate(xrange):\n",
    "        for j, y in enumerate(yrange):\n",
    "            for k, z in enumerate(zrange):\n",
    "                centers[i, j, k, :] = np.array([x, y, z])\n",
    "\n",
    "    centers = centers.reshape((-1, 3))\n",
    "    \n",
    "    voxel_features = np.zeros((len(centers), features.shape[1]), dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(binding_pocket.atoms)):\n",
    "        # Get the coordinates of the current atom\n",
    "        atom_coordinate = atom_coords[i]\n",
    "        \n",
    "        # Get the closest voxel and it's 26 neighbors\n",
    "        voxel_distances = spatial.distance.cdist(atom_coordinate.reshape((-1, 3)), centers).reshape(-1)\n",
    "        c_voxel_ids = voxel_distances.argsort()[:27]\n",
    "        c_voxel_dist = np.sort(voxel_distances)[:27]\n",
    "                \n",
    "        # Calculate the potential\n",
    "        x = features[i] / c_voxel_dist.reshape(-1)[:, np.newaxis]\n",
    "        n = 1.0 - np.exp(-np.power(x, 12))\n",
    "        \n",
    "        # Get the maximum and assign\n",
    "        max_feat = np.maximum(voxel_features[c_voxel_ids], n)\n",
    "        \n",
    "        voxel_features[c_voxel_ids] = n #features[i]\n",
    "        \n",
    "    voxel_features = voxel_features.reshape((N[0], N[1], N[2], -1))\n",
    "    \n",
    "    return _reshape(voxel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156946a5976243eb8611cf4ef12c94ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/ipykernel_launcher.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  import sys\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #623 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #266 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #666 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #629 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdb_ids = []\n",
    "pdb_features = []\n",
    "\n",
    "# Get the features for all the pdbbind refined complexes\n",
    "for pdbid in tqdm_notebook(pdbbind_dataset.sets['refined'].keys()):\n",
    "    feat = get_voxel_features2(pdbid=pdbid, pdbbind_set='refined')\n",
    "    if feat == None: continue    \n",
    "\n",
    "    # Save features\n",
    "    pdb_ids.append(pdbid)\n",
    "    pdb_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3765, 24, 24, 24, 16) (3765,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of features as numpy array\n",
    "data_x = np.array(pdb_features, dtype=np.float32)\n",
    "data_y = np.array([pdbbind_dataset.sets['refined'][_id] for _id in pdb_ids], dtype=np.float32)\n",
    "\n",
    "print(data_x.shape, data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3012, 24, 24, 24, 16) (377, 24, 24, 24, 16) (376, 24, 24, 24, 16)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, random_state=1)\n",
    "test_x, valid_x, test_y, valid_y = train_test_split(test_x, test_y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "h5f = h5py.File(os.path.join(data_dir, \"data_distributed2.h5\"), 'w')\n",
    "h5f.create_dataset('train_x', data=train_x)\n",
    "h5f.create_dataset('train_y', data=train_y)\n",
    "h5f.create_dataset('valid_x', data=valid_x)\n",
    "h5f.create_dataset('valid_y', data=valid_y)\n",
    "h5f.create_dataset('test_x', data=test_x)\n",
    "h5f.create_dataset('test_y', data=test_y)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Canonically Oriented Nearest Neighbor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coordinates(binding_pocket):\n",
    "    # Get the filters for protein and ligands\n",
    "    filter_proteins = [atom.residue.name != 'HOH' for atom in binding_pocket.atoms]\n",
    "    filter_ligands = [atom.residue.name == 'HOH' for atom in binding_pocket.atoms]\n",
    "    \n",
    "    # Get the coordinates for proteins and ligands\n",
    "    coords = binding_pocket.atom_dict['coords']\n",
    "    protein_coords = coords[filter_proteins]\n",
    "    ligand_coords = coords[filter_ligands]\n",
    "    \n",
    "    #Find the centroid of the ligand structure and move the points around that.\n",
    "    l_centroid = np.mean(ligand_coords, axis=0)\n",
    "    protein_coords = protein_coords - l_centroid\n",
    "    ligand_coords = ligand_coords - l_centroid\n",
    "    \n",
    "    try:\n",
    "        # Perform PCA on ligand points\n",
    "        pca = PCA(n_components=3)\n",
    "        pca.fit(ligand_coords)\n",
    "\n",
    "        # x_axis is the first principal component\n",
    "        x_axis = pca.components_[:, 0]\n",
    "\n",
    "        # Get the centroid of the protein points\n",
    "        p_centroid = np.mean(protein_coords, axis=0)\n",
    "\n",
    "        # Projection of p_centroid vector on x_axis\n",
    "        proj_x = np.matmul(np.transpose(x_axis), p_centroid)/np.matmul(np.transpose(x_axis), x_axis) * x_axis\n",
    "        # Get y-axis\n",
    "        y_axis = p_centroid - proj_x\n",
    "\n",
    "        #Normalize\n",
    "        y_axis = y_axis / np.linalg.norm(y_axis)\n",
    "\n",
    "        # z_axis is perpendicular to both x_axis and y_axis. Not sure about the direction yet (+ or - ?)\n",
    "        z_axis = np.cross(x_axis, y_axis)\n",
    "\n",
    "        # Transformation matrix (as column vector and normalized)\n",
    "        R = np.transpose(np.array([x_axis, y_axis, z_axis]))\n",
    "\n",
    "        # Transform all protein and ligand points\n",
    "        mol_coords = coords.reshape((-1, 3))\n",
    "        transformed_coords = np.transpose(np.matmul(R, np.transpose(mol_coords))).reshape((-1, 3))\n",
    "\n",
    "        # Save the coordinates back to the original binding pocket\n",
    "        binding_pocket.coords = transformed_coords\n",
    "\n",
    "        return binding_pocket\n",
    "    except:\n",
    "        global error_count \n",
    "        error_count = error_count + 1\n",
    "        return binding_pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get voxel features (Nearest neighbor feature)\n",
    "\n",
    "def get_voxel_features3(pdbid, pdbbind_set='refined'):\n",
    "    if pdbbind_set == 'refined':\n",
    "        # Don't use the core set\n",
    "        if pdbid in pdbbind_dataset.sets['core'].keys():\n",
    "            #print(\"ERROR: PDBID {} IS IN CORE SET.\".format(pdbid))\n",
    "            return None\n",
    "    \n",
    "    # Read the binding pocket file\n",
    "    pdb_object = PDB(home=pdbbind_dir, pocket_dir=binding_pocket_dir, pdbid=pdbid)\n",
    "    \n",
    "    # If the binding pocket file has any error, return None\n",
    "    if pdb_object == None or pdb_object.pocket == None:\n",
    "        #print(\"ERROR: INVALID BINDING POCKET FOR PDBID {}.\".format(pdbid))\n",
    "        return None\n",
    "    \n",
    "    # Get the Canonically transformed binding pocket\n",
    "    binding_pocket = transform_coordinates(pdb_object.pocket)\n",
    "    \n",
    "    # Get the filters for protein and ligands\n",
    "    filter_proteins = [atom.residue.name != 'HOH' for atom in binding_pocket.atoms]\n",
    "    filter_ligands = [atom.residue.name == 'HOH' for atom in binding_pocket.atoms]\n",
    "    \n",
    "    # Get the properties\n",
    "    is_hydrophobic = binding_pocket.atom_dict['ishydrophobe'].reshape((-1, 1))\n",
    "    is_aromatic = binding_pocket.atom_dict['isaromatic'].reshape((-1, 1))\n",
    "    is_hbond_acceptor = binding_pocket.atom_dict['isacceptor'].reshape((-1, 1))\n",
    "    is_hbond_donor = binding_pocket.atom_dict['isdonor'].reshape((-1, 1))\n",
    "    charges = binding_pocket.atom_dict['charge']\n",
    "    is_positive = (charges < 0.0).reshape((-1, 1))\n",
    "    is_negative = (charges >= 0.0).reshape((-1, 1))\n",
    "    is_metal = binding_pocket.atom_dict['ismetal'].reshape((-1, 1))\n",
    "    is_halogen = binding_pocket.atom_dict['ishalogen'].reshape((-1, 1))\n",
    "    atom_coords = binding_pocket.atom_dict['coords']\n",
    "    properties = np.concatenate((is_hydrophobic,\n",
    "                                 is_aromatic, \n",
    "                                 is_hbond_acceptor, \n",
    "                                 is_hbond_donor, \n",
    "                                 is_positive, \n",
    "                                 is_negative, \n",
    "                                 is_metal, \n",
    "                                 is_halogen), axis=1)\n",
    "    \n",
    "    \n",
    "    # Now get the Van Dar Wals redii for each of the atoms\n",
    "    vdw_radii = np.array([element_radii[ELEMENTS[a.atomicnum].symbol] for a in binding_pocket.atoms], dtype=np.float32)\n",
    "        \n",
    "    # Multiply the vdw radii with the properties. False's will be zeros and True's will be the vdw radii\n",
    "    properties = vdw_radii[:, np.newaxis] * properties\n",
    "    \n",
    "    # Get the features for proteins and ligands\n",
    "    features = np.zeros((len(binding_pocket.atoms), 16))\n",
    "    features[filter_proteins, :8] = properties[filter_proteins]\n",
    "    features[filter_ligands, 8:] = properties[filter_ligands]\n",
    "    \n",
    "    # Get the bounding box for the molecule\n",
    "    max_coord = np.max(atom_coords, axis=0) # np.squeeze?\n",
    "    min_coord = np.min(atom_coords, axis=0) # np.squeeze?\n",
    "\n",
    "    # Calculate the number of voxels required\n",
    "    voxel_side = 2\n",
    "    N = np.ceil((max_coord - min_coord) / voxel_side).astype(int) + 1\n",
    "\n",
    "    # Get the centers of each descriptors\n",
    "    xrange = [min_coord[0] + voxel_side * x for x in range(0, N[0])]\n",
    "    yrange = [min_coord[1] + voxel_side * x for x in range(0, N[1])]\n",
    "    zrange = [min_coord[2] + voxel_side * x for x in range(0, N[2])]\n",
    "    centers = np.zeros((N[0], N[1], N[2], 3))\n",
    "\n",
    "    for i, x in enumerate(xrange):\n",
    "        for j, y in enumerate(yrange):\n",
    "            for k, z in enumerate(zrange):\n",
    "                centers[i, j, k, :] = np.array([x, y, z])\n",
    "\n",
    "    centers = centers.reshape((-1, 3))\n",
    "    \n",
    "    voxel_features = np.zeros((len(centers), features.shape[1]), dtype=np.float32)\n",
    "    for i in range(len(binding_pocket.atoms)):\n",
    "        # Get the coordinates of the current atom\n",
    "        atom_coordinate = atom_coords[i]\n",
    "        \n",
    "        # Get the closest voxel\n",
    "        c_voxel_id = spatial.distance.cdist(atom_coordinate.reshape((-1, 3)), centers).argmin()\n",
    "        c_voxel = centers[c_voxel_id] # nearest voxel\n",
    "        \n",
    "        # Calculate the potential\n",
    "        voxel_distance = np.linalg.norm(atom_coordinate - c_voxel)\n",
    "        x = features[i] / voxel_distance\n",
    "        n = 1.0 - np.exp(-np.power(x, 12))\n",
    "        voxel_features[c_voxel_id] = n #features[i]\n",
    "        \n",
    "    voxel_features = voxel_features.reshape((N[0], N[1], N[2], -1))\n",
    "    \n",
    "    return _reshape(voxel_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not possible to do PCA on some of the pdb complexes. Because sometimes the number of ligand atoms are not enough to perform that operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8e8b8bbd44408ab6b4dba8248ca540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/ipykernel_launcher.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/sklearn/decomposition/pca.py:423: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ = (S ** 2) / (n_samples - 1)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #666 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #629 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #623 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #266 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pdb_ids = []\n",
    "pdb_features = []\n",
    "\n",
    "# Get the features for all the pdbbind refined complexes\n",
    "for pdbid in tqdm_notebook(pdbbind_dataset.sets['refined'].keys()):\n",
    "    try:\n",
    "        feat = get_voxel_features3(pdbid=pdbid, pdbbind_set='refined') # Get the features from Canonically oriented molecule\n",
    "    except:\n",
    "        continue\n",
    "    if feat == None: continue    \n",
    "\n",
    "    # Save features\n",
    "    pdb_ids.append(pdbid)\n",
    "    pdb_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3764, 24, 24, 24, 16) (3764,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of features as numpy array\n",
    "data_x = np.array(pdb_features, dtype=np.float32)\n",
    "data_y = np.array([pdbbind_dataset.sets['refined'][_id] for _id in pdb_ids], dtype=np.float32)\n",
    "\n",
    "print(data_x.shape, data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3011, 24, 24, 24, 16) (377, 24, 24, 24, 16) (376, 24, 24, 24, 16)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, random_state=1)\n",
    "test_x, valid_x, test_y, valid_y = train_test_split(test_x, test_y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "h5f = h5py.File(os.path.join(data_dir, \"data_cano_nearest_neighbor.h5\"), 'w')\n",
    "h5f.create_dataset('train_x', data=train_x)\n",
    "h5f.create_dataset('train_y', data=train_y)\n",
    "h5f.create_dataset('valid_x', data=valid_x)\n",
    "h5f.create_dataset('valid_y', data=valid_y)\n",
    "h5f.create_dataset('test_x', data=test_x)\n",
    "h5f.create_dataset('test_y', data=test_y)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Canonically Oriented  Distributed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get voxel features (distributed features)\n",
    "\n",
    "def get_voxel_features4(pdbid, pdbbind_set='refined'):\n",
    "    if pdbbind_set == 'refined':\n",
    "        # Don't use the core set\n",
    "        if pdbid in pdbbind_dataset.sets['core'].keys():\n",
    "            #print(\"ERROR: PDBID {} IS IN CORE SET.\".format(pdbid))\n",
    "            return None\n",
    "    \n",
    "    # Read the binding pocket file\n",
    "    pdb_object = PDB(home=pdbbind_dir, pocket_dir=binding_pocket_dir, pdbid=pdbid)\n",
    "    \n",
    "    # If the binding pocket file has any error, return None\n",
    "    if pdb_object == None or pdb_object.pocket == None:\n",
    "        #print(\"ERROR: INVALID BINDING POCKET FOR PDBID {}.\".format(pdbid))\n",
    "        return None\n",
    "    \n",
    "    # Get the Canonically transformed binding pocket\n",
    "    binding_pocket = transform_coordinates(pdb_object.pocket)\n",
    "    \n",
    "    # Get the filters for protein and ligands\n",
    "    filter_proteins = [atom.residue.name != 'HOH' for atom in binding_pocket.atoms]\n",
    "    filter_ligands = [atom.residue.name == 'HOH' for atom in binding_pocket.atoms]\n",
    "    \n",
    "    # Get the properties\n",
    "    is_hydrophobic = binding_pocket.atom_dict['ishydrophobe'].reshape((-1, 1))\n",
    "    is_aromatic = binding_pocket.atom_dict['isaromatic'].reshape((-1, 1))\n",
    "    is_hbond_acceptor = binding_pocket.atom_dict['isacceptor'].reshape((-1, 1))\n",
    "    is_hbond_donor = binding_pocket.atom_dict['isdonor'].reshape((-1, 1))\n",
    "    charges = binding_pocket.atom_dict['charge']\n",
    "    is_positive = (charges < 0.0).reshape((-1, 1))\n",
    "    is_negative = (charges >= 0.0).reshape((-1, 1))\n",
    "    is_metal = binding_pocket.atom_dict['ismetal'].reshape((-1, 1))\n",
    "    is_halogen = binding_pocket.atom_dict['ishalogen'].reshape((-1, 1))\n",
    "    atom_coords = binding_pocket.atom_dict['coords']\n",
    "    properties = np.concatenate((is_hydrophobic,\n",
    "                                 is_aromatic, \n",
    "                                 is_hbond_acceptor, \n",
    "                                 is_hbond_donor, \n",
    "                                 is_positive, \n",
    "                                 is_negative, \n",
    "                                 is_metal, \n",
    "                                 is_halogen), axis=1)\n",
    "    \n",
    "    \n",
    "    # Now get the Van Dar Wals redii for each of the atoms\n",
    "    vdw_radii = np.array([element_radii[ELEMENTS[a.atomicnum].symbol] for a in binding_pocket.atoms], dtype=np.float32)\n",
    "        \n",
    "    # Multiply the vdw radii with the properties. False's will be zeros and True's will be the vdw radii\n",
    "    properties = vdw_radii[:, np.newaxis] * properties\n",
    "    \n",
    "    # Get the features for proteins and ligands\n",
    "    features = np.zeros((len(binding_pocket.atoms), 16))\n",
    "    features[filter_proteins, :8] = properties[filter_proteins]\n",
    "    features[filter_ligands, 8:] = properties[filter_ligands]\n",
    "    \n",
    "    # Get the bounding box for the molecule\n",
    "    max_coord = np.max(atom_coords, axis=0) # np.squeeze?\n",
    "    min_coord = np.min(atom_coords, axis=0) # np.squeeze?\n",
    "\n",
    "    # Calculate the number of voxels required\n",
    "    voxel_side = 2\n",
    "    N = np.ceil((max_coord - min_coord) / voxel_side).astype(int) + 1\n",
    "\n",
    "    # Get the centers of each descriptors\n",
    "    xrange = [min_coord[0] + voxel_side * x for x in range(0, N[0])]\n",
    "    yrange = [min_coord[1] + voxel_side * x for x in range(0, N[1])]\n",
    "    zrange = [min_coord[2] + voxel_side * x for x in range(0, N[2])]\n",
    "    centers = np.zeros((N[0], N[1], N[2], 3))\n",
    "\n",
    "    for i, x in enumerate(xrange):\n",
    "        for j, y in enumerate(yrange):\n",
    "            for k, z in enumerate(zrange):\n",
    "                centers[i, j, k, :] = np.array([x, y, z])\n",
    "\n",
    "    centers = centers.reshape((-1, 3))\n",
    "    \n",
    "    voxel_features = np.zeros((len(centers), features.shape[1]), dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(binding_pocket.atoms)):\n",
    "        # Get the coordinates of the current atom\n",
    "        atom_coordinate = atom_coords[i]\n",
    "        \n",
    "        # Get the closest voxel and it's 8 neighbors\n",
    "        voxel_distances = spatial.distance.cdist(atom_coordinate.reshape((-1, 3)), centers).reshape(-1)\n",
    "        c_voxel_ids = voxel_distances.argsort()[:27]\n",
    "        c_voxel_dist = np.sort(voxel_distances)[:27]\n",
    "                \n",
    "        # Calculate the potential\n",
    "        x = features[i] / c_voxel_dist.reshape(-1)[:, np.newaxis]\n",
    "        n = 1.0 - np.exp(-np.power(x, 12))\n",
    "        \n",
    "        # Get the maximum and assign\n",
    "        max_feat = np.maximum(voxel_features[c_voxel_ids], n)\n",
    "        \n",
    "        voxel_features[c_voxel_ids] = n #features[i]\n",
    "        \n",
    "    voxel_features = voxel_features.reshape((N[0], N[1], N[2], -1))\n",
    "    \n",
    "    return _reshape(voxel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406fd7be3ef483c9bf6008695875eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/ipykernel_launcher.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/sklearn/decomposition/pca.py:423: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ = (S ** 2) / (n_samples - 1)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #623 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #266 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #666 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n",
      "/home/mhassan/anaconda3/envs/htmd/lib/python3.5/site-packages/oddt/toolkits/ob.py:474: UserWarning: Error while parsing molecule \"\" for `atom_dict`. Atom #629 (Mn) has 7 neighbors (max_neighbors=6). Additional neighbors are ignored.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdb_ids = []\n",
    "pdb_features = []\n",
    "\n",
    "# Get the features for all the pdbbind refined complexes\n",
    "for pdbid in tqdm_notebook(pdbbind_dataset.sets['refined'].keys()):\n",
    "    try:\n",
    "        feat = get_voxel_features4(pdbid=pdbid, pdbbind_set='refined') # Get the features from Canonically oriented molecule\n",
    "    except:\n",
    "        continue\n",
    "    if feat == None: continue    \n",
    "\n",
    "    # Save features\n",
    "    pdb_ids.append(pdbid)\n",
    "    pdb_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3764, 24, 24, 24, 16) (3764,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of features as numpy array\n",
    "data_x = np.array(pdb_features, dtype=np.float32)\n",
    "data_y = np.array([pdbbind_dataset.sets['refined'][_id] for _id in pdb_ids], dtype=np.float32)\n",
    "\n",
    "print(data_x.shape, data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3011, 24, 24, 24, 16) (377, 24, 24, 24, 16) (376, 24, 24, 24, 16)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, random_state=1)\n",
    "test_x, valid_x, test_y, valid_y = train_test_split(test_x, test_y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "h5f = h5py.File(os.path.join(data_dir, \"data_cano_distributed2.h5\"), 'w')\n",
    "h5f.create_dataset('train_x', data=train_x)\n",
    "h5f.create_dataset('train_y', data=train_y)\n",
    "h5f.create_dataset('valid_x', data=valid_x)\n",
    "h5f.create_dataset('valid_y', data=valid_y)\n",
    "h5f.create_dataset('test_x', data=test_x)\n",
    "h5f.create_dataset('test_y', data=test_y)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
