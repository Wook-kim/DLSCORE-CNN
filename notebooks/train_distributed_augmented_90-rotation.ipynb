{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Add, merge, concatenate\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.pooling import MaxPooling3D, GlobalAveragePooling3D, AveragePooling3D\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import he_uniform\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"models/\")\n",
    "sys.path.append(\"scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4, 5, 6, 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_classes import DataGenerator, AugmentedDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3012, 24, 24, 24, 16) (377, 24, 24, 24, 16) (376, 24, 24, 24, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "h5f = h5py.File('data/data_distributed2.h5', 'r')\n",
    "train_x, train_y = h5f['train_x'][:], h5f['train_y'][:]\n",
    "valid_x, valid_y = h5f['valid_x'][:], h5f['valid_y'][:]\n",
    "test_x, test_y = h5f['test_x'][:], h5f['test_y'][:]\n",
    "h5f.close()\n",
    "\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Squeeze_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "# model_input = Input(shape=(24, 24, 24, 16))\n",
    "# squeeze_model = Model(inputs=model_input, outputs=Squeeze_model(model_input))\n",
    "# #plot_model(squeeze_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "# SVG(model_to_dot(squeeze_model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))\n",
    "# # plot_model(get_model4((24, 24, 24, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "nb_gpus = 4\n",
    "nb_batch = nb_gpus*4\n",
    "nb_epochs = 100\n",
    "l_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "outputFolder = './weights'\n",
    "# if not os.path.exists(outputFolder):\n",
    "#     os.makedirs(outputFolder)\n",
    "\n",
    "filepath=outputFolder+\"/weights-distributed_rotated_90.h5\"\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(filepath, \n",
    "                                  monitor='val_loss',\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=True,\n",
    "                                  mode='auto', period=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=(24, 24, 24, 16))\n",
    "squeeze_model = Model(inputs=model_input, outputs=Squeeze_model(model_input))\n",
    "model = multi_gpu_model(squeeze_model, gpus=nb_gpus)\n",
    "\n",
    "model.compile(optimizer=optimizers.adam(lr=l_rate),# beta_1=0.99, beta_2=0.999),\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_data_gen = AugmentedDataGenerator(x=train_x, y=train_y, batch_size=nb_batch)\n",
    "aug_val_gen = AugmentedDataGenerator(x=valid_x, y=valid_y, batch_size=nb_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 24, 24, 24, 16) (384,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in aug_data_gen:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 137s 726ms/step - loss: 2.1448 - val_loss: 1.6145\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61446, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 135s 717ms/step - loss: 1.6900 - val_loss: 1.5300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61446 to 1.52996, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 128s 683ms/step - loss: 1.6538 - val_loss: 1.4249\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.52996 to 1.42492, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 132s 700ms/step - loss: 1.5582 - val_loss: 1.7223\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 130s 693ms/step - loss: 1.5514 - val_loss: 1.5567\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 131s 699ms/step - loss: 1.5537 - val_loss: 1.4759\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 129s 685ms/step - loss: 1.4791 - val_loss: 1.4539\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 130s 693ms/step - loss: 1.5742 - val_loss: 1.4148\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.42492 to 1.41480, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 133s 710ms/step - loss: 1.5385 - val_loss: 1.3378\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.41480 to 1.33779, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 129s 684ms/step - loss: 1.4838 - val_loss: 1.2816\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.33779 to 1.28163, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 135s 719ms/step - loss: 1.4594 - val_loss: 1.6547\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 143s 761ms/step - loss: 1.4672 - val_loss: 1.2729\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.28163 to 1.27292, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 147s 782ms/step - loss: 1.4506 - val_loss: 1.3416\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 139s 740ms/step - loss: 1.4388 - val_loss: 1.2656\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.27292 to 1.26556, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 131s 694ms/step - loss: 1.4262 - val_loss: 1.4584\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 132s 701ms/step - loss: 1.3739 - val_loss: 1.3672\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 132s 702ms/step - loss: 1.3701 - val_loss: 1.3134\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 133s 707ms/step - loss: 1.4233 - val_loss: 1.4329\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 129s 689ms/step - loss: 1.4064 - val_loss: 1.7054\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 131s 699ms/step - loss: 1.3384 - val_loss: 1.3955\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 130s 690ms/step - loss: 1.3190 - val_loss: 1.2664\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 131s 694ms/step - loss: 1.3255 - val_loss: 1.2746\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 131s 695ms/step - loss: 1.3412 - val_loss: 1.5982\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 135s 717ms/step - loss: 1.2994 - val_loss: 1.3348\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 138s 732ms/step - loss: 1.2763 - val_loss: 1.3523\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 135s 719ms/step - loss: 1.2749 - val_loss: 1.4565\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 142s 757ms/step - loss: 1.2313 - val_loss: 1.2609\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.26556 to 1.26086, saving model to ./weights/weights-distributed_rotated_90.h5\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 161s 859ms/step - loss: 1.2341 - val_loss: 1.2916\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 156s 827ms/step - loss: 1.2184 - val_loss: 1.3989\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 159s 845ms/step - loss: 1.2012 - val_loss: 1.4274\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 156s 828ms/step - loss: 1.1551 - val_loss: 1.5289\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 157s 833ms/step - loss: 1.1570 - val_loss: 1.3833\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 196s 1s/step - loss: 1.1120 - val_loss: 1.3896\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 191s 1s/step - loss: 1.0471 - val_loss: 1.3482\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 261s 1s/step - loss: 1.0164 - val_loss: 1.3608\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 190s 1s/step - loss: 0.9747 - val_loss: 1.4231\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 264s 1s/step - loss: 0.9879 - val_loss: 1.4308\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 190s 1s/step - loss: 0.9426 - val_loss: 1.4398\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 273s 1s/step - loss: 0.9299 - val_loss: 1.4824\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 193s 1s/step - loss: 0.9284 - val_loss: 1.3877\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 286s 2s/step - loss: 0.8843 - val_loss: 1.4417\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 197s 1s/step - loss: 0.8786 - val_loss: 1.4050\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 289s 2s/step - loss: 0.8394 - val_loss: 1.3945\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 207s 1s/step - loss: 0.8109 - val_loss: 1.4294\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 310s 2s/step - loss: 0.7815 - val_loss: 1.4554\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 275s 1s/step - loss: 0.7740 - val_loss: 1.5282\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 211s 1s/step - loss: 0.7550 - val_loss: 1.4494\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 304s 2s/step - loss: 0.7372 - val_loss: 1.4911\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 206s 1s/step - loss: 0.7415 - val_loss: 1.5246\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 301s 2s/step - loss: 0.6973 - val_loss: 1.4776\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 222s 1s/step - loss: 0.6809 - val_loss: 1.4447\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 301s 2s/step - loss: 0.6675 - val_loss: 1.4842\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 216s 1s/step - loss: 0.6626 - val_loss: 1.3691\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 309s 2s/step - loss: 0.6378 - val_loss: 1.4838\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 198s 1s/step - loss: 0.6343 - val_loss: 1.4642\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.6107 - val_loss: 1.4871\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 256s 1s/step - loss: 0.5874 - val_loss: 1.4787\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 244s 1s/step - loss: 0.5928 - val_loss: 1.5691\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.5761 - val_loss: 1.4944\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 203s 1s/step - loss: 0.5598 - val_loss: 1.5242\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 291s 2s/step - loss: 0.5726 - val_loss: 1.5435\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 204s 1s/step - loss: 0.5399 - val_loss: 1.4635\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 233s 1s/step - loss: 0.5379 - val_loss: 1.5452\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 247s 1s/step - loss: 0.5110 - val_loss: 1.5133\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 196s 1s/step - loss: 0.4972 - val_loss: 1.5187\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 324s 2s/step - loss: 0.5001 - val_loss: 1.5296\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 201s 1s/step - loss: 0.4934 - val_loss: 1.5243\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 314s 2s/step - loss: 0.4737 - val_loss: 1.5359\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 211s 1s/step - loss: 0.4585 - val_loss: 1.5487\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 318s 2s/step - loss: 0.4789 - val_loss: 1.5425\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 207s 1s/step - loss: 0.4560 - val_loss: 1.5332\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.4589 - val_loss: 1.4940\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 306s 2s/step - loss: 0.4467 - val_loss: 1.4656\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 218s 1s/step - loss: 0.4439 - val_loss: 1.4898\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 324s 2s/step - loss: 0.4130 - val_loss: 1.4993\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 220s 1s/step - loss: 0.4383 - val_loss: 1.4741\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 318s 2s/step - loss: 0.4219 - val_loss: 1.5744\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 226s 1s/step - loss: 0.4060 - val_loss: 1.5641\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 315s 2s/step - loss: 0.3987 - val_loss: 1.5485\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 219s 1s/step - loss: 0.4125 - val_loss: 1.5904\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 272s 1s/step - loss: 0.3968 - val_loss: 1.5177\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 297s 2s/step - loss: 0.3801 - val_loss: 1.5030\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 224s 1s/step - loss: 0.3911 - val_loss: 1.5353\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 349s 2s/step - loss: 0.3704 - val_loss: 1.4425\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 236s 1s/step - loss: 0.3678 - val_loss: 1.5675\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 326s 2s/step - loss: 0.3711 - val_loss: 1.5035\n",
      "\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 245s 1s/step - loss: 0.3607 - val_loss: 1.5373\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 341s 2s/step - loss: 0.3467 - val_loss: 1.5185\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 247s 1s/step - loss: 0.3633 - val_loss: 1.5231\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 367s 2s/step - loss: 0.3455 - val_loss: 1.5326\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 309s 2s/step - loss: 0.3446 - val_loss: 1.5403\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 240s 1s/step - loss: 0.3290 - val_loss: 1.5921\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 373s 2s/step - loss: 0.3351 - val_loss: 1.5262\n",
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 248s 1s/step - loss: 0.3239 - val_loss: 1.5341\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 359s 2s/step - loss: 0.3432 - val_loss: 1.5319\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 255s 1s/step - loss: 0.3284 - val_loss: 1.4928\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 350s 2s/step - loss: 0.3247 - val_loss: 1.6157\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 242s 1s/step - loss: 0.3334 - val_loss: 1.5120\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 335s 2s/step - loss: 0.3121 - val_loss: 1.5455\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 347s 2s/step - loss: 0.3069 - val_loss: 1.5553\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=aug_data_gen, validation_data=aug_val_gen,\n",
    "                              use_multiprocessing=False, \n",
    "                              epochs=nb_epochs, \n",
    "                              max_queue_size=5, \n",
    "                              workers=56, \n",
    "                              verbose=1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(outputFolder, \"history_distributed_rotated-90.pickle\"), 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First 100 epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 (without average):  0.4044429632970251\n",
      "Train r2 (with average):  0.4555838570815747\n",
      "Test r2 (without average):  0.3497966032527091\n",
      "Test r2 (with average):  0.40481611752360336\n"
     ]
    }
   ],
   "source": [
    "sample_size = 200\n",
    "rotation_count = 24 # Because it's 90 degree rotation\n",
    "\n",
    "train_aug_data_gen = AugmentedDataGenerator(x=train_x,\n",
    "                                            y=train_y,\n",
    "                                            batch_size=sample_size)\n",
    "# Two chunks to avoid memory issues\n",
    "test_aug_data_gen= AugmentedDataGenerator(x=test_x[:sample_size],\n",
    "                                            y=test_y[:sample_size],\n",
    "                                            batch_size=sample_size)\n",
    "\n",
    "# Train r2\n",
    "\n",
    "for x, y in train_aug_data_gen:\n",
    "    # Without average\n",
    "    train_r2 = r2_score(y_true=y, y_pred=model.predict(x))\n",
    "    print(\"Train r2 (without average): \", train_r2)\n",
    "    \n",
    "    # With average\n",
    "    y_pred = model.predict(x)[:, 0]\n",
    "    \n",
    "    sample_y = np.zeros(sample_size)\n",
    "    sample_ypred = np.zeros(sample_size)\n",
    "    for i in range(sample_size):\n",
    "        start = i*rotation_count\n",
    "        end = i*rotation_count + rotation_count\n",
    "        mean_ypred = np.mean(y_pred[start:end])\n",
    "        mean_y = np.mean(y[start:end])\n",
    "        sample_ypred[i] = mean_ypred\n",
    "        sample_y[i] = mean_y\n",
    "    \n",
    "    train_r2 = r2_score(y_true=sample_y, y_pred=sample_ypred)\n",
    "    print(\"Train r2 (with average): \", train_r2)\n",
    "    break\n",
    "    \n",
    "#sample_size = test_x.shape[0]\n",
    "    \n",
    "# Test r2\n",
    "\n",
    "for x, y in test_aug_data_gen:\n",
    "    # Without average\n",
    "    test_r2 = r2_score(y_true=y, y_pred=model.predict(x))\n",
    "    print(\"Test r2 (without average): \", test_r2)\n",
    "    \n",
    "    # With average\n",
    "    y_pred = model.predict(x)[:, 0]\n",
    "    \n",
    "    sample_y = np.zeros(sample_size)\n",
    "    sample_ypred = np.zeros(sample_size)\n",
    "    for i in range(sample_size):\n",
    "        start = i*rotation_count\n",
    "        end = i*rotation_count + rotation_count\n",
    "        mean_ypred = np.mean(y_pred[start:end])\n",
    "        mean_y = np.mean(y[start:end])\n",
    "        sample_ypred[i] = mean_ypred\n",
    "        sample_y[i] = mean_y\n",
    "    \n",
    "    test_r2 = r2_score(y_true=sample_y, y_pred=sample_ypred)\n",
    "    print(\"Test r2 (with average): \", test_r2)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
